{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'dataSet/ONLINE EDUCATION SYSTEM REVIEW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data\n",
    "# drop the grade column\n",
    "df = df.drop(columns=\"Average marks scored before pandemic in traditional classroom\")\n",
    "# split data to inputs and target\n",
    "inputs = df.drop(columns=[\"Performance in online\",\"Your level of satisfaction in Online Education\"])\n",
    "inputs = pd.DataFrame(inputs)\n",
    "inputs.head(5)\n",
    "target = df[\"Your level of satisfaction in Online Education\"]\n",
    "target = pd.DataFrame(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocssing inputs\n",
    "#declare catergory columns\n",
    "category = [\"Gender\", \"Home Location\", \"Level of Education\",\"Device type used to attend classes\",\"Economic status\",\"Are you involved in any sports?\",\"Do elderly people monitor you?\",\"Interested in Gaming?\",\"Have separate room for studying?\",\"Engaged in group studies?\",\"Interested in?\"]\n",
    "\n",
    "# print(\"before encoded\")\n",
    "# for i in category:\n",
    "#     unique = np.unique(inputs[i])\n",
    "#     print(i)\n",
    "#     print(unique)\n",
    "\n",
    "for i in category:\n",
    "    inputs[i]=inputs[i].astype(\"category\")\n",
    "    inputs[i]=inputs[i].replace(np.nan, 0)\n",
    "    # number encoded the category item\n",
    "    unique = np.unique(inputs[i])\n",
    "    for j,z in zip(unique,range(len(unique))):\n",
    "        inputs[i] = inputs[i].replace(j,z)\n",
    "\n",
    "# print(\"after encoded\")\n",
    "# for i in category:\n",
    "#     unique = np.unique(inputs[i])\n",
    "#     print(i)\n",
    "#     print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert inputs into one-hot-encoded\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "base =os.curdir\n",
    "\n",
    "def one_hot_encode(column, df):\n",
    "    encoder = OneHotEncoder(sparse = False)\n",
    "    seleted_col = df[[column]]\n",
    "    encoder.fit(seleted_col)\n",
    "    encoded = encoder.transform(seleted_col)\n",
    "    encoded = pd.DataFrame(data=encoded,columns=encoder.categories_)\n",
    "    return encoded\n",
    "\n",
    "def one_hot_encoding(inputs):\n",
    "    for x in inputs:\n",
    "        encoded_col = one_hot_encode(x,inputs)\n",
    "        inputs.drop(x,axis=1,inplace =True)\n",
    "        for y in encoded_col.columns:\n",
    "            path = str(x)+str(y)\n",
    "            path = str(path)\n",
    "            path = path.replace(\"'\",\"\")\n",
    "            path = path.replace(\",\",\"\")\n",
    "            inputs.insert(len(inputs.columns),path,encoded_col[y])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 20)\n",
      "(1033, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2         3         4    5    6      7     8    9    10  \\\n",
       "0  1.0  1.0  1.0  0.290323  0.526316  0.5  0.0  0.250  1.00  0.0  1.0   \n",
       "1  1.0  1.0  1.0  0.322581  0.315789  0.5  0.0  0.250  0.00  1.0  1.0   \n",
       "2  1.0  0.0  1.0  0.290323  0.210526  0.5  0.0  0.375  0.25  0.0  1.0   \n",
       "3  1.0  1.0  1.0  0.290323  0.210526  0.5  0.0  0.250  0.75  1.0  1.0   \n",
       "4  1.0  0.0  1.0  0.290323  0.210526  0.5  0.0  0.250  0.50  0.0  0.0   \n",
       "\n",
       "         11        12        13   14   15   16   17    18   19  \n",
       "0  0.222222  0.555556  0.000000  0.0  0.0  0.0  0.0  0.00  0.5  \n",
       "1  0.666667  0.444444  0.000000  1.0  1.0  0.0  0.0  0.00  1.0  \n",
       "2  0.555556  0.666667  0.000000  0.0  1.0  0.0  0.0  0.00  0.0  \n",
       "3  0.222222  0.555556  0.111111  0.0  0.0  1.0  0.0  0.25  1.0  \n",
       "4  0.777778  0.666667  0.111111  1.0  1.0  1.0  0.5  0.50  0.0  "
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = one_hot_encoding(inputs)\n",
    "# inputs.head(5)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# scale inputs\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(inputs)\n",
    "print(inputs.shape)\n",
    "print(scaled.shape)\n",
    "inputs = pd.DataFrame(scaled)\n",
    "inputs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Your level of satisfaction in Online Education(Average)</th>\n",
       "      <th>Your level of satisfaction in Online Education(Bad)</th>\n",
       "      <th>Your level of satisfaction in Online Education(Good)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Your level of satisfaction in Online Education(Average)  \\\n",
       "0                                                1.0         \n",
       "1                                                0.0         \n",
       "2                                                0.0         \n",
       "3                                                0.0         \n",
       "4                                                1.0         \n",
       "\n",
       "   Your level of satisfaction in Online Education(Bad)  \\\n",
       "0                                                0.0     \n",
       "1                                                1.0     \n",
       "2                                                1.0     \n",
       "3                                                1.0     \n",
       "4                                                0.0     \n",
       "\n",
       "   Your level of satisfaction in Online Education(Good)  \n",
       "0                                                0.0     \n",
       "1                                                0.0     \n",
       "2                                                0.0     \n",
       "3                                                0.0     \n",
       "4                                                0.0     "
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing target\n",
    "unique = np.unique(target)\n",
    "# number encoded target\n",
    "# for i, j in zip(unique,range(len(unique))):\n",
    "#     target = target.replace(i,j)\n",
    "\n",
    "target = one_hot_encoding(target)\n",
    "    \n",
    "target.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 20)\n",
      "(1033, 3)\n"
     ]
    }
   ],
   "source": [
    "inputs= inputs.values\n",
    "target = target.values\n",
    "print(inputs.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "model = Sequential([\n",
    "    layers.Dense(15, input_dim = 20, activation = 'relu'), # Rectified Linear Unit Activation Function\n",
    "    layers.Dense(10, activation = 'relu'),\n",
    "    layers.Dense(5, activation = 'relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(3, activation = 'softmax') # Softmax for multi-class classification\n",
    "])\n",
    "    # Compile model here\n",
    "model.compile(optimizer='adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, target, test_size=0.2, random_state=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 10\n",
    "# np.random.seed(seed)\n",
    "# estimator = KerasClassifier(build_fn = model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "\n",
    "# kfold = KFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "\n",
    "# results = cross_val_score(estimator, inputs, target, cv = kfold)\n",
    "# print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "9/9 [==============================] - 1s 20ms/step - loss: 1.1337 - accuracy: 0.2397 - val_loss: 1.1116 - val_accuracy: 0.3092\n",
      "Epoch 2/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.1143 - accuracy: 0.2748 - val_loss: 1.1041 - val_accuracy: 0.3430\n",
      "Epoch 3/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.1023 - accuracy: 0.3305 - val_loss: 1.0976 - val_accuracy: 0.3816\n",
      "Epoch 4/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.0913 - accuracy: 0.4492 - val_loss: 1.0926 - val_accuracy: 0.3768\n",
      "Epoch 5/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0856 - accuracy: 0.4806 - val_loss: 1.0882 - val_accuracy: 0.4493\n",
      "Epoch 6/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0784 - accuracy: 0.5048 - val_loss: 1.0841 - val_accuracy: 0.4686\n",
      "Epoch 7/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0740 - accuracy: 0.5206 - val_loss: 1.0801 - val_accuracy: 0.4928\n",
      "Epoch 8/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0695 - accuracy: 0.5242 - val_loss: 1.0769 - val_accuracy: 0.4976\n",
      "Epoch 9/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0631 - accuracy: 0.5315 - val_loss: 1.0732 - val_accuracy: 0.4976\n",
      "Epoch 10/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0572 - accuracy: 0.5291 - val_loss: 1.0698 - val_accuracy: 0.5024\n",
      "Epoch 11/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.0510 - accuracy: 0.5254 - val_loss: 1.0671 - val_accuracy: 0.5121\n",
      "Epoch 12/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.0428 - accuracy: 0.5242 - val_loss: 1.0648 - val_accuracy: 0.5072\n",
      "Epoch 13/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0369 - accuracy: 0.5291 - val_loss: 1.0625 - val_accuracy: 0.5072\n",
      "Epoch 14/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.0321 - accuracy: 0.5266 - val_loss: 1.0604 - val_accuracy: 0.5072\n",
      "Epoch 15/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0200 - accuracy: 0.5375 - val_loss: 1.0586 - val_accuracy: 0.5024\n",
      "Epoch 16/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0151 - accuracy: 0.5387 - val_loss: 1.0577 - val_accuracy: 0.5024\n",
      "Epoch 17/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0091 - accuracy: 0.5327 - val_loss: 1.0500 - val_accuracy: 0.5072\n",
      "Epoch 18/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0097 - accuracy: 0.5363 - val_loss: 1.0416 - val_accuracy: 0.5024\n",
      "Epoch 19/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0036 - accuracy: 0.5375 - val_loss: 1.0417 - val_accuracy: 0.5217\n",
      "Epoch 20/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9962 - accuracy: 0.5315 - val_loss: 1.0372 - val_accuracy: 0.5217\n",
      "Epoch 21/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9734 - accuracy: 0.5436 - val_loss: 1.0291 - val_accuracy: 0.5217\n",
      "Epoch 22/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9844 - accuracy: 0.5400 - val_loss: 1.0251 - val_accuracy: 0.5314\n",
      "Epoch 23/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.9729 - accuracy: 0.5400 - val_loss: 1.0141 - val_accuracy: 0.5217\n",
      "Epoch 24/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9563 - accuracy: 0.5412 - val_loss: 1.0027 - val_accuracy: 0.5169\n",
      "Epoch 25/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9567 - accuracy: 0.5472 - val_loss: 0.9983 - val_accuracy: 0.5169\n",
      "Epoch 26/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9417 - accuracy: 0.5508 - val_loss: 0.9998 - val_accuracy: 0.5314\n",
      "Epoch 27/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9404 - accuracy: 0.5412 - val_loss: 0.9970 - val_accuracy: 0.5362\n",
      "Epoch 28/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9536 - accuracy: 0.5218 - val_loss: 0.9865 - val_accuracy: 0.5459\n",
      "Epoch 29/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9309 - accuracy: 0.5472 - val_loss: 0.9850 - val_accuracy: 0.5507\n",
      "Epoch 30/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9265 - accuracy: 0.5400 - val_loss: 0.9724 - val_accuracy: 0.5507\n",
      "Epoch 31/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9210 - accuracy: 0.5690 - val_loss: 0.9723 - val_accuracy: 0.5556\n",
      "Epoch 32/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9162 - accuracy: 0.5472 - val_loss: 0.9655 - val_accuracy: 0.5556\n",
      "Epoch 33/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9124 - accuracy: 0.5436 - val_loss: 0.9574 - val_accuracy: 0.5556\n",
      "Epoch 34/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9124 - accuracy: 0.5436 - val_loss: 0.9553 - val_accuracy: 0.5652\n",
      "Epoch 35/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8969 - accuracy: 0.5557 - val_loss: 0.9509 - val_accuracy: 0.5604\n",
      "Epoch 36/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8934 - accuracy: 0.5642 - val_loss: 0.9467 - val_accuracy: 0.5700\n",
      "Epoch 37/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8725 - accuracy: 0.5811 - val_loss: 0.9441 - val_accuracy: 0.5652\n",
      "Epoch 38/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8699 - accuracy: 0.5860 - val_loss: 0.9409 - val_accuracy: 0.5894\n",
      "Epoch 39/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8882 - accuracy: 0.5690 - val_loss: 0.9338 - val_accuracy: 0.5845\n",
      "Epoch 40/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.6029 - val_loss: 0.9311 - val_accuracy: 0.5942\n",
      "Epoch 41/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8508 - accuracy: 0.5920 - val_loss: 0.9247 - val_accuracy: 0.5942\n",
      "Epoch 42/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8602 - accuracy: 0.6005 - val_loss: 0.9287 - val_accuracy: 0.5845\n",
      "Epoch 43/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8640 - accuracy: 0.5847 - val_loss: 0.9311 - val_accuracy: 0.5990\n",
      "Epoch 44/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8543 - accuracy: 0.5981 - val_loss: 0.9219 - val_accuracy: 0.5990\n",
      "Epoch 45/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8523 - accuracy: 0.5956 - val_loss: 0.9379 - val_accuracy: 0.6087\n",
      "Epoch 46/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8233 - accuracy: 0.6102 - val_loss: 0.9159 - val_accuracy: 0.6087\n",
      "Epoch 47/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8478 - accuracy: 0.5944 - val_loss: 0.9246 - val_accuracy: 0.6087\n",
      "Epoch 48/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8413 - accuracy: 0.5993 - val_loss: 0.9231 - val_accuracy: 0.6087\n",
      "Epoch 49/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8386 - accuracy: 0.5908 - val_loss: 0.9249 - val_accuracy: 0.5990\n",
      "Epoch 50/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8338 - accuracy: 0.5969 - val_loss: 0.9235 - val_accuracy: 0.5942\n",
      "Epoch 51/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8253 - accuracy: 0.6041 - val_loss: 0.9243 - val_accuracy: 0.5894\n",
      "Epoch 52/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8294 - accuracy: 0.6017 - val_loss: 0.9209 - val_accuracy: 0.5894\n",
      "Epoch 53/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8249 - accuracy: 0.5920 - val_loss: 0.9188 - val_accuracy: 0.5845\n",
      "Epoch 54/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8355 - accuracy: 0.5932 - val_loss: 0.9235 - val_accuracy: 0.5845\n",
      "Epoch 55/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8199 - accuracy: 0.6174 - val_loss: 0.9186 - val_accuracy: 0.5845\n",
      "Epoch 56/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8232 - accuracy: 0.6114 - val_loss: 0.9285 - val_accuracy: 0.5942\n",
      "Epoch 57/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.6077 - val_loss: 0.9187 - val_accuracy: 0.5797\n",
      "Epoch 58/250\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8145 - accuracy: 0.6150 - val_loss: 0.9235 - val_accuracy: 0.5894\n",
      "Epoch 59/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8065 - accuracy: 0.5884 - val_loss: 0.9191 - val_accuracy: 0.5845\n",
      "Epoch 60/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8178 - accuracy: 0.5908 - val_loss: 0.9201 - val_accuracy: 0.5845\n",
      "Epoch 61/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8115 - accuracy: 0.6090 - val_loss: 0.9269 - val_accuracy: 0.5990\n",
      "Epoch 62/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8115 - accuracy: 0.6235 - val_loss: 0.9272 - val_accuracy: 0.5942\n",
      "Epoch 63/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7930 - accuracy: 0.6344 - val_loss: 0.9263 - val_accuracy: 0.5942\n",
      "Epoch 64/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8045 - accuracy: 0.6114 - val_loss: 0.9268 - val_accuracy: 0.5894\n",
      "Epoch 65/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7987 - accuracy: 0.6150 - val_loss: 0.9267 - val_accuracy: 0.5845\n",
      "Epoch 66/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8022 - accuracy: 0.6186 - val_loss: 0.9316 - val_accuracy: 0.5942\n",
      "Epoch 67/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7884 - accuracy: 0.6174 - val_loss: 0.9320 - val_accuracy: 0.5990\n",
      "Epoch 68/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7986 - accuracy: 0.6344 - val_loss: 0.9280 - val_accuracy: 0.6087\n",
      "Epoch 69/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8132 - accuracy: 0.6017 - val_loss: 0.9262 - val_accuracy: 0.6039\n",
      "Epoch 70/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8080 - accuracy: 0.6223 - val_loss: 0.9338 - val_accuracy: 0.6135\n",
      "Epoch 71/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8021 - accuracy: 0.6235 - val_loss: 0.9293 - val_accuracy: 0.5942\n",
      "Epoch 72/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8045 - accuracy: 0.6065 - val_loss: 0.9325 - val_accuracy: 0.6087\n",
      "Epoch 73/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8077 - accuracy: 0.6235 - val_loss: 0.9315 - val_accuracy: 0.6135\n",
      "Epoch 74/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8041 - accuracy: 0.6211 - val_loss: 0.9330 - val_accuracy: 0.6039\n",
      "Epoch 75/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.6199 - val_loss: 0.9284 - val_accuracy: 0.5942\n",
      "Epoch 76/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7918 - accuracy: 0.6174 - val_loss: 0.9359 - val_accuracy: 0.6135\n",
      "Epoch 77/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7908 - accuracy: 0.6283 - val_loss: 0.9361 - val_accuracy: 0.6184\n",
      "Epoch 78/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7898 - accuracy: 0.6150 - val_loss: 0.9323 - val_accuracy: 0.6039\n",
      "Epoch 79/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7819 - accuracy: 0.6441 - val_loss: 0.9423 - val_accuracy: 0.6087\n",
      "Epoch 80/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7794 - accuracy: 0.6344 - val_loss: 0.9435 - val_accuracy: 0.5845\n",
      "Epoch 81/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.6283 - val_loss: 0.9367 - val_accuracy: 0.5749\n",
      "Epoch 82/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7750 - accuracy: 0.6295 - val_loss: 0.9412 - val_accuracy: 0.5990\n",
      "Epoch 83/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.6199 - val_loss: 0.9463 - val_accuracy: 0.5990\n",
      "Epoch 84/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7964 - accuracy: 0.6223 - val_loss: 0.9341 - val_accuracy: 0.5942\n",
      "Epoch 85/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7851 - accuracy: 0.6332 - val_loss: 0.9409 - val_accuracy: 0.5942\n",
      "Epoch 86/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7896 - accuracy: 0.6235 - val_loss: 0.9374 - val_accuracy: 0.5990\n",
      "Epoch 87/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7945 - accuracy: 0.6174 - val_loss: 0.9403 - val_accuracy: 0.5942\n",
      "Epoch 88/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7765 - accuracy: 0.6223 - val_loss: 0.9433 - val_accuracy: 0.5894\n",
      "Epoch 89/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7818 - accuracy: 0.6235 - val_loss: 0.9488 - val_accuracy: 0.6039\n",
      "Epoch 90/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7802 - accuracy: 0.6247 - val_loss: 0.9412 - val_accuracy: 0.6039\n",
      "Epoch 91/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7907 - accuracy: 0.6283 - val_loss: 0.9458 - val_accuracy: 0.6039\n",
      "Epoch 92/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7885 - accuracy: 0.6283 - val_loss: 0.9397 - val_accuracy: 0.6087\n",
      "Epoch 93/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7943 - accuracy: 0.6199 - val_loss: 0.9418 - val_accuracy: 0.5942\n",
      "Epoch 94/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7724 - accuracy: 0.6404 - val_loss: 0.9476 - val_accuracy: 0.5894\n",
      "Epoch 95/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7831 - accuracy: 0.6162 - val_loss: 0.9412 - val_accuracy: 0.6039\n",
      "Epoch 96/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7735 - accuracy: 0.6295 - val_loss: 0.9485 - val_accuracy: 0.5797\n",
      "Epoch 97/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7712 - accuracy: 0.6332 - val_loss: 0.9426 - val_accuracy: 0.5990\n",
      "Epoch 98/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.6416 - val_loss: 0.9501 - val_accuracy: 0.5797\n",
      "Epoch 99/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7931 - accuracy: 0.6186 - val_loss: 0.9416 - val_accuracy: 0.6039\n",
      "Epoch 100/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7683 - accuracy: 0.6368 - val_loss: 0.9512 - val_accuracy: 0.5845\n",
      "Epoch 101/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.6271 - val_loss: 0.9430 - val_accuracy: 0.6039\n",
      "Epoch 102/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7622 - accuracy: 0.6477 - val_loss: 0.9458 - val_accuracy: 0.6087\n",
      "Epoch 103/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.6344 - val_loss: 0.9523 - val_accuracy: 0.5845\n",
      "Epoch 104/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7748 - accuracy: 0.6271 - val_loss: 0.9477 - val_accuracy: 0.6039\n",
      "Epoch 105/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7763 - accuracy: 0.6380 - val_loss: 0.9517 - val_accuracy: 0.5894\n",
      "Epoch 106/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7667 - accuracy: 0.6283 - val_loss: 0.9548 - val_accuracy: 0.5894\n",
      "Epoch 107/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7662 - accuracy: 0.6259 - val_loss: 0.9478 - val_accuracy: 0.5942\n",
      "Epoch 108/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7626 - accuracy: 0.6332 - val_loss: 0.9540 - val_accuracy: 0.5894\n",
      "Epoch 109/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7730 - accuracy: 0.6320 - val_loss: 0.9557 - val_accuracy: 0.5894\n",
      "Epoch 110/250\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7730 - accuracy: 0.6368 - val_loss: 0.9466 - val_accuracy: 0.5942\n",
      "Epoch 111/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7664 - accuracy: 0.6271 - val_loss: 0.9557 - val_accuracy: 0.5894\n",
      "Epoch 112/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7819 - accuracy: 0.6259 - val_loss: 0.9570 - val_accuracy: 0.5749\n",
      "Epoch 113/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7588 - accuracy: 0.6368 - val_loss: 0.9523 - val_accuracy: 0.5942\n",
      "Epoch 114/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7764 - accuracy: 0.6344 - val_loss: 0.9573 - val_accuracy: 0.5749\n",
      "Epoch 115/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7519 - accuracy: 0.6453 - val_loss: 0.9557 - val_accuracy: 0.5845\n",
      "Epoch 116/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7634 - accuracy: 0.6247 - val_loss: 0.9507 - val_accuracy: 0.5845\n",
      "Epoch 117/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7677 - accuracy: 0.6453 - val_loss: 0.9608 - val_accuracy: 0.5894\n",
      "Epoch 118/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7461 - accuracy: 0.6501 - val_loss: 0.9556 - val_accuracy: 0.5942\n",
      "Epoch 119/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7536 - accuracy: 0.6453 - val_loss: 0.9635 - val_accuracy: 0.5845\n",
      "Epoch 120/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7596 - accuracy: 0.6441 - val_loss: 0.9628 - val_accuracy: 0.5845\n",
      "Epoch 121/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7612 - accuracy: 0.6453 - val_loss: 0.9587 - val_accuracy: 0.5942\n",
      "Epoch 122/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7640 - accuracy: 0.6513 - val_loss: 0.9561 - val_accuracy: 0.5990\n",
      "Epoch 123/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7593 - accuracy: 0.6416 - val_loss: 0.9594 - val_accuracy: 0.5990\n",
      "Epoch 124/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.6368 - val_loss: 0.9656 - val_accuracy: 0.5700\n",
      "Epoch 125/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7605 - accuracy: 0.6525 - val_loss: 0.9644 - val_accuracy: 0.5749\n",
      "Epoch 126/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7560 - accuracy: 0.6489 - val_loss: 0.9649 - val_accuracy: 0.5797\n",
      "Epoch 127/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7435 - accuracy: 0.6634 - val_loss: 0.9645 - val_accuracy: 0.5942\n",
      "Epoch 128/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7560 - accuracy: 0.6465 - val_loss: 0.9665 - val_accuracy: 0.5990\n",
      "Epoch 129/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7492 - accuracy: 0.6489 - val_loss: 0.9695 - val_accuracy: 0.5845\n",
      "Epoch 130/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7620 - accuracy: 0.6308 - val_loss: 0.9665 - val_accuracy: 0.6087\n",
      "Epoch 131/250\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7570 - accuracy: 0.6441 - val_loss: 0.9740 - val_accuracy: 0.5894\n",
      "Epoch 132/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7679 - accuracy: 0.6271 - val_loss: 0.9660 - val_accuracy: 0.5797\n",
      "Epoch 133/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7531 - accuracy: 0.6392 - val_loss: 0.9718 - val_accuracy: 0.5749\n",
      "Epoch 134/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.6477 - val_loss: 0.9699 - val_accuracy: 0.5894\n",
      "Epoch 135/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7501 - accuracy: 0.6598 - val_loss: 0.9625 - val_accuracy: 0.5990\n",
      "Epoch 136/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.6368 - val_loss: 0.9740 - val_accuracy: 0.5990\n",
      "Epoch 137/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7519 - accuracy: 0.6344 - val_loss: 0.9742 - val_accuracy: 0.5845\n",
      "Epoch 138/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7471 - accuracy: 0.6465 - val_loss: 0.9646 - val_accuracy: 0.5942\n",
      "Epoch 139/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7493 - accuracy: 0.6356 - val_loss: 0.9713 - val_accuracy: 0.6039\n",
      "Epoch 140/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.6562 - val_loss: 0.9673 - val_accuracy: 0.5942\n",
      "Epoch 141/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.6550 - val_loss: 0.9783 - val_accuracy: 0.5845\n",
      "Epoch 142/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7638 - accuracy: 0.6186 - val_loss: 0.9778 - val_accuracy: 0.5700\n",
      "Epoch 143/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7484 - accuracy: 0.6525 - val_loss: 0.9762 - val_accuracy: 0.5942\n",
      "Epoch 144/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7451 - accuracy: 0.6501 - val_loss: 0.9774 - val_accuracy: 0.5942\n",
      "Epoch 145/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7489 - accuracy: 0.6550 - val_loss: 0.9720 - val_accuracy: 0.5894\n",
      "Epoch 146/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7458 - accuracy: 0.6416 - val_loss: 0.9814 - val_accuracy: 0.5990\n",
      "Epoch 147/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7291 - accuracy: 0.6634 - val_loss: 0.9767 - val_accuracy: 0.5845\n",
      "Epoch 148/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7439 - accuracy: 0.6392 - val_loss: 0.9724 - val_accuracy: 0.5797\n",
      "Epoch 149/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.6489 - val_loss: 0.9796 - val_accuracy: 0.5845\n",
      "Epoch 150/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7375 - accuracy: 0.6453 - val_loss: 0.9878 - val_accuracy: 0.5749\n",
      "Epoch 151/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.6513 - val_loss: 0.9767 - val_accuracy: 0.5942\n",
      "Epoch 152/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.6538 - val_loss: 0.9815 - val_accuracy: 0.6135\n",
      "Epoch 153/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7398 - accuracy: 0.6562 - val_loss: 0.9847 - val_accuracy: 0.5990\n",
      "Epoch 154/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7463 - accuracy: 0.6416 - val_loss: 0.9745 - val_accuracy: 0.5942\n",
      "Epoch 155/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7554 - accuracy: 0.6453 - val_loss: 0.9869 - val_accuracy: 0.5990\n",
      "Epoch 156/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7344 - accuracy: 0.6586 - val_loss: 0.9855 - val_accuracy: 0.5894\n",
      "Epoch 157/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7517 - accuracy: 0.6368 - val_loss: 0.9827 - val_accuracy: 0.5990\n",
      "Epoch 158/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.6743 - val_loss: 0.9831 - val_accuracy: 0.5990\n",
      "Epoch 159/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7357 - accuracy: 0.6489 - val_loss: 0.9783 - val_accuracy: 0.6232\n",
      "Epoch 160/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.6465 - val_loss: 0.9809 - val_accuracy: 0.6039\n",
      "Epoch 161/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.6562 - val_loss: 0.9811 - val_accuracy: 0.6039\n",
      "Epoch 162/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7284 - accuracy: 0.6574 - val_loss: 0.9943 - val_accuracy: 0.6039\n",
      "Epoch 163/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.6308 - val_loss: 0.9825 - val_accuracy: 0.5990\n",
      "Epoch 164/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7331 - accuracy: 0.6598 - val_loss: 0.9883 - val_accuracy: 0.6135\n",
      "Epoch 165/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.6671 - val_loss: 0.9854 - val_accuracy: 0.6039\n",
      "Epoch 166/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7464 - accuracy: 0.6525 - val_loss: 0.9864 - val_accuracy: 0.6087\n",
      "Epoch 167/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7207 - accuracy: 0.6707 - val_loss: 0.9905 - val_accuracy: 0.6039\n",
      "Epoch 168/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.6380 - val_loss: 0.9874 - val_accuracy: 0.6087\n",
      "Epoch 169/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7308 - accuracy: 0.6477 - val_loss: 0.9886 - val_accuracy: 0.6087\n",
      "Epoch 170/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7173 - accuracy: 0.6731 - val_loss: 0.9954 - val_accuracy: 0.5894\n",
      "Epoch 171/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.6646 - val_loss: 0.9927 - val_accuracy: 0.6087\n",
      "Epoch 172/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7309 - accuracy: 0.6477 - val_loss: 0.9938 - val_accuracy: 0.5942\n",
      "Epoch 173/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.6562 - val_loss: 0.9953 - val_accuracy: 0.6087\n",
      "Epoch 174/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.6501 - val_loss: 0.9957 - val_accuracy: 0.6087\n",
      "Epoch 175/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.6550 - val_loss: 0.9931 - val_accuracy: 0.5942\n",
      "Epoch 176/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.6513 - val_loss: 1.0010 - val_accuracy: 0.6087\n",
      "Epoch 177/250\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7249 - accuracy: 0.6671 - val_loss: 1.0005 - val_accuracy: 0.6039\n",
      "Epoch 178/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7316 - accuracy: 0.6465 - val_loss: 0.9996 - val_accuracy: 0.6087\n",
      "Epoch 179/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7134 - accuracy: 0.6513 - val_loss: 1.0037 - val_accuracy: 0.6039\n",
      "Epoch 180/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.6695 - val_loss: 1.0056 - val_accuracy: 0.5942\n",
      "Epoch 181/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7408 - accuracy: 0.6525 - val_loss: 0.9962 - val_accuracy: 0.6039\n",
      "Epoch 182/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.6586 - val_loss: 0.9951 - val_accuracy: 0.6039\n",
      "Epoch 183/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7172 - accuracy: 0.6622 - val_loss: 0.9986 - val_accuracy: 0.5894\n",
      "Epoch 184/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7315 - accuracy: 0.6501 - val_loss: 0.9968 - val_accuracy: 0.6039\n",
      "Epoch 185/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.6719 - val_loss: 1.0046 - val_accuracy: 0.5845\n",
      "Epoch 186/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7078 - accuracy: 0.6695 - val_loss: 1.0002 - val_accuracy: 0.6184\n",
      "Epoch 187/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.6768 - val_loss: 1.0051 - val_accuracy: 0.5942\n",
      "Epoch 188/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.6622 - val_loss: 1.0018 - val_accuracy: 0.6184\n",
      "Epoch 189/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.6525 - val_loss: 1.0113 - val_accuracy: 0.6087\n",
      "Epoch 190/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.6731 - val_loss: 1.0056 - val_accuracy: 0.6039\n",
      "Epoch 191/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.6598 - val_loss: 1.0042 - val_accuracy: 0.6087\n",
      "Epoch 192/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.6646 - val_loss: 1.0098 - val_accuracy: 0.5942\n",
      "Epoch 193/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7192 - accuracy: 0.6634 - val_loss: 1.0078 - val_accuracy: 0.6135\n",
      "Epoch 194/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7237 - accuracy: 0.6562 - val_loss: 1.0109 - val_accuracy: 0.6135\n",
      "Epoch 195/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7190 - accuracy: 0.6683 - val_loss: 1.0043 - val_accuracy: 0.6232\n",
      "Epoch 196/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.6404 - val_loss: 1.0061 - val_accuracy: 0.6232\n",
      "Epoch 197/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.6368 - val_loss: 1.0115 - val_accuracy: 0.6039\n",
      "Epoch 198/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7337 - accuracy: 0.6477 - val_loss: 1.0081 - val_accuracy: 0.6135\n",
      "Epoch 199/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.6755 - val_loss: 1.0157 - val_accuracy: 0.5845\n",
      "Epoch 200/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.6707 - val_loss: 1.0059 - val_accuracy: 0.6184\n",
      "Epoch 201/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.6525 - val_loss: 1.0124 - val_accuracy: 0.6039\n",
      "Epoch 202/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.6743 - val_loss: 1.0114 - val_accuracy: 0.6135\n",
      "Epoch 203/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.6671 - val_loss: 1.0134 - val_accuracy: 0.6135\n",
      "Epoch 204/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.6755 - val_loss: 1.0074 - val_accuracy: 0.6135\n",
      "Epoch 205/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.6768 - val_loss: 1.0181 - val_accuracy: 0.5942\n",
      "Epoch 206/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7180 - accuracy: 0.6622 - val_loss: 1.0160 - val_accuracy: 0.5942\n",
      "Epoch 207/250\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6981 - accuracy: 0.6804 - val_loss: 1.0094 - val_accuracy: 0.6135\n",
      "Epoch 208/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7060 - accuracy: 0.6695 - val_loss: 1.0249 - val_accuracy: 0.5894\n",
      "Epoch 209/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.6574 - val_loss: 1.0205 - val_accuracy: 0.6039\n",
      "Epoch 210/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.6840 - val_loss: 1.0218 - val_accuracy: 0.6135\n",
      "Epoch 211/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7189 - accuracy: 0.6610 - val_loss: 1.0253 - val_accuracy: 0.5894\n",
      "Epoch 212/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.6755 - val_loss: 1.0177 - val_accuracy: 0.6184\n",
      "Epoch 213/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.6501 - val_loss: 1.0148 - val_accuracy: 0.6184\n",
      "Epoch 214/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.6792 - val_loss: 1.0283 - val_accuracy: 0.5894\n",
      "Epoch 215/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.6755 - val_loss: 1.0236 - val_accuracy: 0.5942\n",
      "Epoch 216/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7201 - accuracy: 0.6574 - val_loss: 1.0194 - val_accuracy: 0.6039\n",
      "Epoch 217/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.6598 - val_loss: 1.0181 - val_accuracy: 0.6135\n",
      "Epoch 218/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.6755 - val_loss: 1.0251 - val_accuracy: 0.6039\n",
      "Epoch 219/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.6768 - val_loss: 1.0288 - val_accuracy: 0.5942\n",
      "Epoch 220/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7143 - accuracy: 0.6562 - val_loss: 1.0192 - val_accuracy: 0.6039\n",
      "Epoch 221/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.6671 - val_loss: 1.0269 - val_accuracy: 0.5845\n",
      "Epoch 222/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.6683 - val_loss: 1.0239 - val_accuracy: 0.6039\n",
      "Epoch 223/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.6755 - val_loss: 1.0313 - val_accuracy: 0.5942\n",
      "Epoch 224/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.6828 - val_loss: 1.0305 - val_accuracy: 0.5990\n",
      "Epoch 225/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6864 - val_loss: 1.0316 - val_accuracy: 0.5894\n",
      "Epoch 226/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.6852 - val_loss: 1.0340 - val_accuracy: 0.5990\n",
      "Epoch 227/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.6695 - val_loss: 1.0304 - val_accuracy: 0.6039\n",
      "Epoch 228/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.6719 - val_loss: 1.0321 - val_accuracy: 0.6039\n",
      "Epoch 229/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.6901 - val_loss: 1.0362 - val_accuracy: 0.5990\n",
      "Epoch 230/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.6780 - val_loss: 1.0395 - val_accuracy: 0.5990\n",
      "Epoch 231/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.6707 - val_loss: 1.0393 - val_accuracy: 0.5990\n",
      "Epoch 232/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7040 - accuracy: 0.6792 - val_loss: 1.0401 - val_accuracy: 0.5942\n",
      "Epoch 233/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.6877 - val_loss: 1.0378 - val_accuracy: 0.5942\n",
      "Epoch 234/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.6889 - val_loss: 1.0387 - val_accuracy: 0.5990\n",
      "Epoch 235/250\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.6683 - val_loss: 1.0433 - val_accuracy: 0.5942\n",
      "Epoch 236/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.6755 - val_loss: 1.0476 - val_accuracy: 0.5942\n",
      "Epoch 237/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.6840 - val_loss: 1.0437 - val_accuracy: 0.5990\n",
      "Epoch 238/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.6780 - val_loss: 1.0491 - val_accuracy: 0.6039\n",
      "Epoch 239/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.6780 - val_loss: 1.0436 - val_accuracy: 0.5894\n",
      "Epoch 240/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.6780 - val_loss: 1.0490 - val_accuracy: 0.5894\n",
      "Epoch 241/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.6949 - val_loss: 1.0494 - val_accuracy: 0.5990\n",
      "Epoch 242/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.6901 - val_loss: 1.0475 - val_accuracy: 0.5942\n",
      "Epoch 243/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.6852 - val_loss: 1.0490 - val_accuracy: 0.5942\n",
      "Epoch 244/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.6804 - val_loss: 1.0436 - val_accuracy: 0.5942\n",
      "Epoch 245/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.6852 - val_loss: 1.0434 - val_accuracy: 0.5990\n",
      "Epoch 246/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.6804 - val_loss: 1.0454 - val_accuracy: 0.5942\n",
      "Epoch 247/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.6792 - val_loss: 1.0475 - val_accuracy: 0.5942\n",
      "Epoch 248/250\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7139 - accuracy: 0.6634 - val_loss: 1.0529 - val_accuracy: 0.5845\n",
      "Epoch 249/250\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6877 - val_loss: 1.0481 - val_accuracy: 0.5990\n",
      "Epoch 250/250\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6929 - accuracy: 0.6949 - val_loss: 1.0585 - val_accuracy: 0.5942\n",
      "0.6231883764266968\n",
      "0.9782636165618896\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "epochs=250\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  validation_data = (X_test,y_test),\n",
    "  batch_size = 100,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "print(np.max(val_acc))\n",
    "print(val_loss[np.argmax(val_acc)])\n",
    "print(np.argmax(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5942028985507246\n",
      "Mean Square Error :  1.0289855072463767\n",
      "[0 2 0 2 0]\n",
      "Confusion Matrix for each label : \n",
      "[[[ 47  55]\n",
      "  [ 22  83]]\n",
      "\n",
      " [[148  20]\n",
      "  [ 21  18]]\n",
      "\n",
      " [[135   9]\n",
      "  [ 41  22]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68       105\n",
      "           1       0.47      0.46      0.47        39\n",
      "           2       0.71      0.35      0.47        63\n",
      "\n",
      "    accuracy                           0.59       207\n",
      "   macro avg       0.59      0.53      0.54       207\n",
      "weighted avg       0.61      0.59      0.58       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "prediction = model.predict(X_test)\n",
    "prediction  = np.argmax(prediction, axis=1)\n",
    "y_val=np.argmax(y_test, axis=1)\n",
    "print(\"Accuracy : \", accuracy_score(y_val, prediction))\n",
    "print(\"Mean Square Error : \", mean_squared_error(y_val, prediction))\n",
    "\n",
    "print(prediction[:5])\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(y_val, prediction))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_val, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7871 - accuracy: 0.6469\n",
      "Accuracy for batch  1  :  0.7884615384615384\n",
      "Mean Square Error for batch  1  :  0.7019230769230769\n",
      "33/33 [==============================] - 0s 927us/step - loss: 0.8002 - accuracy: 0.6544\n",
      "Accuracy for batch  2  :  0.75\n",
      "Mean Square Error for batch  2  :  0.5384615384615384\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7842 - accuracy: 0.6370\n",
      "Accuracy for batch  3  :  0.6923076923076923\n",
      "Mean Square Error for batch  3  :  0.5673076923076923\n",
      "33/33 [==============================] - 0s 971us/step - loss: 0.7819 - accuracy: 0.6554\n",
      "Accuracy for batch  4  :  0.6504854368932039\n",
      "Mean Square Error for batch  4  :  0.6407766990291263\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7690 - accuracy: 0.6670\n",
      "Accuracy for batch  5  :  0.7184466019417476\n",
      "Mean Square Error for batch  5  :  0.7184466019417476\n",
      "33/33 [==============================] - 0s 954us/step - loss: 0.7707 - accuracy: 0.6534\n",
      "Accuracy for batch  6  :  0.6504854368932039\n",
      "Mean Square Error for batch  6  :  1.0485436893203883\n",
      "33/33 [==============================] - 0s 966us/step - loss: 0.7681 - accuracy: 0.6573\n",
      "Accuracy for batch  7  :  0.6893203883495146\n",
      "Mean Square Error for batch  7  :  0.8349514563106796\n",
      "33/33 [==============================] - 0s 962us/step - loss: 0.7616 - accuracy: 0.6621\n",
      "Accuracy for batch  8  :  0.7669902912621359\n",
      "Mean Square Error for batch  8  :  0.6407766990291263\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7614 - accuracy: 0.6757\n",
      "Accuracy for batch  9  :  0.6699029126213593\n",
      "Mean Square Error for batch  9  :  1.0\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7534 - accuracy: 0.6667\n",
      "Accuracy for batch  10  :  0.6601941747572816\n",
      "Mean Square Error for batch  10  :  0.8640776699029126\n",
      "Average Accuracy =  0.7036594473487677\n",
      "Average MSE =  0.7555265123226287\n"
     ]
    }
   ],
   "source": [
    "X = inputs\n",
    "y = target\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits=10\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "i = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    #print(train_indices)\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "    \n",
    "    mlp = model\n",
    "    mlp.fit(X[start_train:stop_train], y[start_train:stop_train])\n",
    "    pred = mlp.predict(X[start_test:stop_test])\n",
    "    #pred\n",
    "    i+=1\n",
    "\n",
    "    pred  = np.argmax(pred, axis=1)\n",
    "    y=np.argmax(y, axis=1)\n",
    "    acc += accuracy_score(y[start_test:stop_test], pred)\n",
    "    mse += mean_squared_error(y[start_test:stop_test], pred)\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Accuracy for batch \", i, \" : \", accuracy_score(y[start_test:stop_test], pred))\n",
    "    print(\"Mean Square Error for batch \", i, \" : \", mean_squared_error(y[start_test:stop_test], pred))\n",
    "    X = inputs\n",
    "    y = target\n",
    "\n",
    "print('Average Accuracy = ', acc / n_splits)\n",
    "print('Average MSE = ', mse / n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(15, input_dim = 20, activation = 'relu'))\n",
    "\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=3, max_value=20, step=20)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project nn_kt_dir/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from nn_kt_dir/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 3 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='nn_kt_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(X_train, y_train, epochs=200, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.0291 - accuracy: 0.5076 - val_loss: 0.9900 - val_accuracy: 0.5422\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.5258 - val_loss: 0.9389 - val_accuracy: 0.5422\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9138 - accuracy: 0.5515 - val_loss: 0.8894 - val_accuracy: 0.5663\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8658 - accuracy: 0.5924 - val_loss: 0.8606 - val_accuracy: 0.5843\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8446 - accuracy: 0.5788 - val_loss: 0.8529 - val_accuracy: 0.6145\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8106 - accuracy: 0.6227 - val_loss: 0.8554 - val_accuracy: 0.5964\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7995 - accuracy: 0.6348 - val_loss: 0.8761 - val_accuracy: 0.5904\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8153 - accuracy: 0.6333 - val_loss: 0.8532 - val_accuracy: 0.5602\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7977 - accuracy: 0.6364 - val_loss: 0.8679 - val_accuracy: 0.5723\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7892 - accuracy: 0.6364 - val_loss: 0.8551 - val_accuracy: 0.5723\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7835 - accuracy: 0.6212 - val_loss: 0.8832 - val_accuracy: 0.5663\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7835 - accuracy: 0.6333 - val_loss: 0.8739 - val_accuracy: 0.5542\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7818 - accuracy: 0.6394 - val_loss: 0.8732 - val_accuracy: 0.5783\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7667 - accuracy: 0.6591 - val_loss: 0.8670 - val_accuracy: 0.6084\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7651 - accuracy: 0.6591 - val_loss: 0.9173 - val_accuracy: 0.5241\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7593 - accuracy: 0.6455 - val_loss: 0.8700 - val_accuracy: 0.5964\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.6667 - val_loss: 0.8512 - val_accuracy: 0.5904\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7367 - accuracy: 0.6652 - val_loss: 0.9134 - val_accuracy: 0.5783\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.6606 - val_loss: 0.8816 - val_accuracy: 0.5723\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7508 - accuracy: 0.6652 - val_loss: 0.9127 - val_accuracy: 0.5964\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.6939 - val_loss: 0.9130 - val_accuracy: 0.5843\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.6818 - val_loss: 0.9256 - val_accuracy: 0.5843\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7532 - accuracy: 0.6530 - val_loss: 0.9201 - val_accuracy: 0.5783\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.6591 - val_loss: 0.9236 - val_accuracy: 0.5904\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.7307 - accuracy: 0.6682 - val_loss: 0.9255 - val_accuracy: 0.5783\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.7205 - accuracy: 0.6773 - val_loss: 0.8975 - val_accuracy: 0.6145\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.6939 - val_loss: 0.8972 - val_accuracy: 0.6145\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.6833 - val_loss: 0.8949 - val_accuracy: 0.5783\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.6803 - val_loss: 0.9121 - val_accuracy: 0.5783\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.6788 - val_loss: 0.9877 - val_accuracy: 0.5542\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.6848 - val_loss: 0.9616 - val_accuracy: 0.5783\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.6955 - val_loss: 0.9842 - val_accuracy: 0.5783\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.7000 - val_loss: 0.9403 - val_accuracy: 0.5843\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6909 - val_loss: 0.9975 - val_accuracy: 0.5783\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.7061 - val_loss: 0.9607 - val_accuracy: 0.5843\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.6985 - val_loss: 0.9558 - val_accuracy: 0.5904\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6970 - val_loss: 1.0211 - val_accuracy: 0.5542\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.6894 - val_loss: 1.0034 - val_accuracy: 0.5723\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.7136 - val_loss: 0.9849 - val_accuracy: 0.5723\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.6970 - val_loss: 1.0172 - val_accuracy: 0.5542\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7167 - val_loss: 1.0264 - val_accuracy: 0.5602\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.7136 - val_loss: 0.9676 - val_accuracy: 0.5602\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.7076 - val_loss: 1.0422 - val_accuracy: 0.5602\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6924 - val_loss: 1.0385 - val_accuracy: 0.5482\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.7106 - val_loss: 1.0283 - val_accuracy: 0.5602\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.7136 - val_loss: 1.0443 - val_accuracy: 0.5482\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6985 - val_loss: 1.0448 - val_accuracy: 0.5542\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.7030 - val_loss: 1.0861 - val_accuracy: 0.5482\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.7152 - val_loss: 1.0737 - val_accuracy: 0.5301\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7212 - val_loss: 1.0274 - val_accuracy: 0.5482\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.7182 - val_loss: 1.0284 - val_accuracy: 0.5602\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.7197 - val_loss: 1.0909 - val_accuracy: 0.5602\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.7500 - val_loss: 1.1470 - val_accuracy: 0.5482\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.7045 - val_loss: 1.0188 - val_accuracy: 0.5663\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.7152 - val_loss: 1.1242 - val_accuracy: 0.5542\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.7182 - val_loss: 1.0844 - val_accuracy: 0.5602\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.7242 - val_loss: 1.0736 - val_accuracy: 0.5361\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7379 - val_loss: 1.1477 - val_accuracy: 0.5361\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7621 - val_loss: 1.0817 - val_accuracy: 0.5361\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.7333 - val_loss: 1.1153 - val_accuracy: 0.5301\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.7394 - val_loss: 1.1693 - val_accuracy: 0.5422\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7318 - val_loss: 1.2278 - val_accuracy: 0.5422\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7515 - val_loss: 1.2934 - val_accuracy: 0.5361\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7273 - val_loss: 1.2550 - val_accuracy: 0.5422\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.7424 - val_loss: 1.3572 - val_accuracy: 0.5060\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.7258 - val_loss: 1.2914 - val_accuracy: 0.5241\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.7409 - val_loss: 1.3189 - val_accuracy: 0.5301\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7576 - val_loss: 1.3199 - val_accuracy: 0.5241\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7379 - val_loss: 1.3601 - val_accuracy: 0.5422\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7530 - val_loss: 1.3907 - val_accuracy: 0.5482\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7348 - val_loss: 1.3916 - val_accuracy: 0.5241\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.7318 - val_loss: 1.3890 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7394 - val_loss: 1.2875 - val_accuracy: 0.5422\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7561 - val_loss: 1.2879 - val_accuracy: 0.5181\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7636 - val_loss: 1.4287 - val_accuracy: 0.5181\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7561 - val_loss: 1.5453 - val_accuracy: 0.5060\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 1.2889 - val_accuracy: 0.5241\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7576 - val_loss: 1.4709 - val_accuracy: 0.5241\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7606 - val_loss: 1.5054 - val_accuracy: 0.5181\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7591 - val_loss: 1.4291 - val_accuracy: 0.5120\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7742 - val_loss: 1.6404 - val_accuracy: 0.5663\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7258 - val_loss: 1.5335 - val_accuracy: 0.5181\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7621 - val_loss: 1.4034 - val_accuracy: 0.5422\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7894 - val_loss: 1.4035 - val_accuracy: 0.5060\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7591 - val_loss: 1.5459 - val_accuracy: 0.5422\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7591 - val_loss: 1.6197 - val_accuracy: 0.5181\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7515 - val_loss: 1.4829 - val_accuracy: 0.5422\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7742 - val_loss: 1.5780 - val_accuracy: 0.5060\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7773 - val_loss: 1.6505 - val_accuracy: 0.5422\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7652 - val_loss: 1.5999 - val_accuracy: 0.5181\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7636 - val_loss: 1.5568 - val_accuracy: 0.5361\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7788 - val_loss: 1.4834 - val_accuracy: 0.5301\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7636 - val_loss: 1.4177 - val_accuracy: 0.5301\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7636 - val_loss: 1.6002 - val_accuracy: 0.5301\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7530 - val_loss: 1.5910 - val_accuracy: 0.5301\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7303 - val_loss: 1.4691 - val_accuracy: 0.5602\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7848 - val_loss: 1.6073 - val_accuracy: 0.5361\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7667 - val_loss: 1.4970 - val_accuracy: 0.5422\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7939 - val_loss: 1.6010 - val_accuracy: 0.5361\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7803 - val_loss: 1.6407 - val_accuracy: 0.5482\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7803 - val_loss: 1.7028 - val_accuracy: 0.5361\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7833 - val_loss: 1.5570 - val_accuracy: 0.4940\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7742 - val_loss: 1.6877 - val_accuracy: 0.5482\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7788 - val_loss: 1.6401 - val_accuracy: 0.5120\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8015 - val_loss: 1.7196 - val_accuracy: 0.5301\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7955 - val_loss: 1.5797 - val_accuracy: 0.5120\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7894 - val_loss: 1.8290 - val_accuracy: 0.5422\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.8000 - val_loss: 1.8169 - val_accuracy: 0.5060\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7955 - val_loss: 1.6878 - val_accuracy: 0.5301\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7879 - val_loss: 1.8378 - val_accuracy: 0.5783\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8015 - val_loss: 1.7120 - val_accuracy: 0.5422\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8091 - val_loss: 1.7597 - val_accuracy: 0.5542\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8121 - val_loss: 1.7882 - val_accuracy: 0.5181\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7955 - val_loss: 1.9491 - val_accuracy: 0.5241\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7561 - val_loss: 2.0299 - val_accuracy: 0.5241\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7803 - val_loss: 1.9352 - val_accuracy: 0.5301\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7758 - val_loss: 1.7398 - val_accuracy: 0.5120\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.7409 - val_loss: 1.1287 - val_accuracy: 0.5482\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7515 - val_loss: 1.7751 - val_accuracy: 0.5602\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7879 - val_loss: 1.4956 - val_accuracy: 0.5542\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7894 - val_loss: 1.8454 - val_accuracy: 0.5482\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8136 - val_loss: 1.9275 - val_accuracy: 0.5482\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8076 - val_loss: 1.9812 - val_accuracy: 0.5602\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8121 - val_loss: 1.9946 - val_accuracy: 0.5482\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7848 - val_loss: 2.1016 - val_accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7864 - val_loss: 1.9311 - val_accuracy: 0.5542\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8091 - val_loss: 2.2341 - val_accuracy: 0.5181\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7803 - val_loss: 1.9855 - val_accuracy: 0.5241\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8197 - val_loss: 2.0096 - val_accuracy: 0.5482\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8288 - val_loss: 2.1092 - val_accuracy: 0.5181\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7879 - val_loss: 1.8989 - val_accuracy: 0.5361\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.8030 - val_loss: 1.9085 - val_accuracy: 0.5301\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8000 - val_loss: 1.8242 - val_accuracy: 0.5482\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7955 - val_loss: 1.9881 - val_accuracy: 0.5542\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8136 - val_loss: 2.2004 - val_accuracy: 0.5663\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8061 - val_loss: 2.1957 - val_accuracy: 0.5542\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8030 - val_loss: 2.1430 - val_accuracy: 0.5301\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7924 - val_loss: 2.1125 - val_accuracy: 0.5542\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7924 - val_loss: 2.4144 - val_accuracy: 0.5241\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7758 - val_loss: 1.8290 - val_accuracy: 0.5482\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7833 - val_loss: 1.9674 - val_accuracy: 0.5301\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7924 - val_loss: 2.1050 - val_accuracy: 0.5482\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8167 - val_loss: 2.0532 - val_accuracy: 0.5241\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8136 - val_loss: 1.9559 - val_accuracy: 0.5663\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8152 - val_loss: 2.0690 - val_accuracy: 0.5361\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7985 - val_loss: 2.1907 - val_accuracy: 0.5361\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8061 - val_loss: 2.2915 - val_accuracy: 0.5301\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7894 - val_loss: 1.9531 - val_accuracy: 0.5422\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8152 - val_loss: 2.3709 - val_accuracy: 0.5422\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8258 - val_loss: 2.3051 - val_accuracy: 0.5120\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8167 - val_loss: 2.1546 - val_accuracy: 0.5602\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8242 - val_loss: 2.4561 - val_accuracy: 0.5241\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8061 - val_loss: 2.2258 - val_accuracy: 0.5120\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8045 - val_loss: 2.4449 - val_accuracy: 0.5241\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7818 - val_loss: 1.6359 - val_accuracy: 0.5482\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7742 - val_loss: 2.1614 - val_accuracy: 0.5181\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7879 - val_loss: 2.0410 - val_accuracy: 0.5241\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7985 - val_loss: 2.1306 - val_accuracy: 0.5422\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.8061 - val_loss: 1.9442 - val_accuracy: 0.5301\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8288 - val_loss: 2.2833 - val_accuracy: 0.5361\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.8121 - val_loss: 2.2422 - val_accuracy: 0.5482\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8273 - val_loss: 2.2887 - val_accuracy: 0.5301\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.8121 - val_loss: 2.2850 - val_accuracy: 0.5301\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8045 - val_loss: 2.3460 - val_accuracy: 0.5482\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8152 - val_loss: 2.6158 - val_accuracy: 0.5301\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8136 - val_loss: 2.2421 - val_accuracy: 0.5602\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8182 - val_loss: 2.4990 - val_accuracy: 0.5120\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.8136 - val_loss: 2.5722 - val_accuracy: 0.5241\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8212 - val_loss: 2.4384 - val_accuracy: 0.5542\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7970 - val_loss: 2.1205 - val_accuracy: 0.5361\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8121 - val_loss: 2.5610 - val_accuracy: 0.5361\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8212 - val_loss: 2.7332 - val_accuracy: 0.5301\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8030 - val_loss: 2.2279 - val_accuracy: 0.5602\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7924 - val_loss: 2.4211 - val_accuracy: 0.5422\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7909 - val_loss: 1.8863 - val_accuracy: 0.5542\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7894 - val_loss: 2.1049 - val_accuracy: 0.5602\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8030 - val_loss: 2.4043 - val_accuracy: 0.5361\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8015 - val_loss: 2.2035 - val_accuracy: 0.5422\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8167 - val_loss: 1.8052 - val_accuracy: 0.5422\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8076 - val_loss: 2.5697 - val_accuracy: 0.5060\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7742 - val_loss: 1.8397 - val_accuracy: 0.5482\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8000 - val_loss: 2.5156 - val_accuracy: 0.5482\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8227 - val_loss: 2.0750 - val_accuracy: 0.5482\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8227 - val_loss: 2.3772 - val_accuracy: 0.5542\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8258 - val_loss: 2.6033 - val_accuracy: 0.5422\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8152 - val_loss: 2.3647 - val_accuracy: 0.5422\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8364 - val_loss: 2.7435 - val_accuracy: 0.5301\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8197 - val_loss: 2.4389 - val_accuracy: 0.5241\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.8091 - val_loss: 2.1457 - val_accuracy: 0.5542\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8121 - val_loss: 2.5214 - val_accuracy: 0.5181\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8136 - val_loss: 2.3760 - val_accuracy: 0.5301\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8197 - val_loss: 2.2553 - val_accuracy: 0.5482\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8227 - val_loss: 2.5670 - val_accuracy: 0.5301\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8121 - val_loss: 2.6125 - val_accuracy: 0.5422\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8030 - val_loss: 2.6115 - val_accuracy: 0.5301\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8167 - val_loss: 2.6237 - val_accuracy: 0.5422\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8182 - val_loss: 2.5543 - val_accuracy: 0.5361\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8364 - val_loss: 2.7921 - val_accuracy: 0.5301\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8303 - val_loss: 2.7255 - val_accuracy: 0.5361\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8273 - val_loss: 2.7631 - val_accuracy: 0.4880\n",
      "Best epoch: 5\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 1s 9ms/step - loss: 1.0695 - accuracy: 0.4894 - val_loss: 1.0195 - val_accuracy: 0.5422\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0210 - accuracy: 0.5242 - val_loss: 1.0099 - val_accuracy: 0.5422\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0302 - accuracy: 0.5242 - val_loss: 1.0086 - val_accuracy: 0.5422\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0218 - accuracy: 0.5242 - val_loss: 1.0079 - val_accuracy: 0.5422\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0284 - accuracy: 0.5242 - val_loss: 1.0093 - val_accuracy: 0.5422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e8cef80>"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=200, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0391 - accuracy: 0.5072\n",
      "[test loss, test accuracy]: [1.0391188859939575, 0.5072463750839233]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
